{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "breeding-identifier",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'iris_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-92d858b8158c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m \u001b[0mmodel_lda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iris_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0mIris_setosa_observation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-92d858b8158c>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# read the iris data as a Pandas data frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# separate the class labels from the rest of the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         )\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m             )\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'iris_data.csv'"
     ]
    }
   ],
   "source": [
    "# This is code for Linear Discriminant Analysis\n",
    "# Written by William F Basener\n",
    "# University of Virginia, School of Data Science\n",
    "# For use in teaching Bayesian Machine Learning\n",
    "#\n",
    "# The code currently computes the maximum likelihood classification\n",
    "# Student is to add method to compute posterior probabilities and maximum probability classification\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def multivariate_gaussian_pdf(X, MU, SIGMA):\n",
    "    \"\"\"Code from Data Blog https://xavierbourretsicotte.github.io/MLE_Multivariate_Gaussian.html\n",
    "    Maximum Likelihood Estimator: Multivariate Gaussian Distribution\n",
    "        by Xavier Bourret Sicotte, Fri 22 June 2018\n",
    "    Returns the pdf of a multivariate Gaussian distribution\n",
    "     - X, MU are p x 1 vectors\n",
    "     - SIGMA is a p x p matrix\"\"\"\n",
    "    # Initialize and reshape\n",
    "    X = X.reshape(-1, 1)\n",
    "    MU = MU.reshape(-1, 1)\n",
    "    p, _ = SIGMA.shape\n",
    "\n",
    "    # Compute values\n",
    "    SIGMA_inv = np.linalg.inv(SIGMA)\n",
    "    denominator = np.sqrt((2 * np.pi) ** p * np.linalg.det(SIGMA))\n",
    "    exponent = -(1 / 2) * ((X - MU).T @ SIGMA_inv @ (X - MU))\n",
    "\n",
    "    # Return result\n",
    "    return float((1. / denominator) * np.exp(exponent))\n",
    "\n",
    "\n",
    "class LDA:\n",
    "    \"\"\"Creates a class for Linear Discriminant Analysis\n",
    "    Input:\n",
    "        fname = file name for a csv file, must have one column labeled \"class\" and the rest numeric data\n",
    "    Methods:\n",
    "        compute_probabilities = given an input observation computes the likelihood for each class and the GML class\n",
    "        compute_probabilities: given an input observation and prior probabilities,\n",
    "            computes the posterior probabilities for each class and most probable class\"\"\"\n",
    "\n",
    "    def __init__(self, fname):\n",
    "        # reads the data and computes the statistics needed for classification\n",
    "\n",
    "        # read the iris data as a Pandas data frame\n",
    "        df = pd.read_csv(fname)\n",
    "\n",
    "        # separate the class labels from the rest of the data\n",
    "        # we are assuming the column name with class labels is 'Class'\n",
    "        # and all other columns are numeric\n",
    "        self.data_labels = df.loc[:]['Class']\n",
    "        self.data = np.asarray(df.drop('Class', axis=1, inplace=False))\n",
    "\n",
    "        # get information about the dimensions the data\n",
    "        self.num_rows, self.num_cols = self.data.shape\n",
    "\n",
    "        # get the class names as an array of strings\n",
    "        self.class_names = np.unique(self.data_labels)\n",
    "\n",
    "        # determine number of observations in each class\n",
    "        self.num_obs = dict()\n",
    "        for name in self.class_names:\n",
    "            self.num_obs[name] = sum(self.data_labels == name)\n",
    "\n",
    "        # compute the mean of each class\n",
    "        self.means = dict()\n",
    "        for name in self.class_names:\n",
    "            self.means[name] = np.mean(self.data[self.data_labels == name, :], 0)\n",
    "\n",
    "        # compute the mean covariance matrix\n",
    "        self.cov = np.zeros([self.num_cols, self.num_cols])\n",
    "        for name in self.class_names:\n",
    "            self.cov = self.cov + self.num_obs[name] * np.cov(np.transpose(self.data[self.data_labels == name, :]))\n",
    "        self.cov = self.cov / self.num_rows\n",
    "\n",
    "    def compute_likelihoods(self, x):\n",
    "        # compute and output the likelihood of each class and the maximum likelihood class\n",
    "\n",
    "        # check that the input data x has the correct number of rows\n",
    "        if not (len(x) == self.num_cols):\n",
    "            print('Data vector has wrong number of values.')\n",
    "            return -1\n",
    "\n",
    "        # reformat x as a numpy array, incase the user input a list\n",
    "        x = np.asarray(x)\n",
    "\n",
    "        # compute the likelihood of each class\n",
    "        likelihoods = np.zeros(len(self.class_names))\n",
    "        idx = 0\n",
    "        for name in self.class_names:\n",
    "            likelihoods[idx] = multivariate_gaussian_pdf(x, self.means[name], self.cov)\n",
    "            idx = idx + 1\n",
    "\n",
    "        # get the indices for sorting the likelihoods (in descending order)\n",
    "        indices_sorted = np.argsort(likelihoods)[::-1]\n",
    "\n",
    "        # print the predicted class and all class likelihoods\n",
    "        print('LDA Predicted Class: ' + self.class_names[indices_sorted[0]])\n",
    "        print('LDA Class Likelihoods:')\n",
    "        for idx in range(len(indices_sorted)):\n",
    "            print(self.class_names[indices_sorted[idx]] + ': ' + str(likelihoods[indices_sorted[idx]]))\n",
    "\n",
    "        # return the likelihoods\n",
    "        return likelihoods\n",
    "\n",
    "    def compute_probabilities(self, x, priors):\n",
    "        # compute and output the probability of each class and the maximum probability class\n",
    "\n",
    "        # check that the input data x has the correct number of rows\n",
    "        if not (len(x) == self.num_cols):\n",
    "            print('Data vector has wrong number of values.')\n",
    "            return -1\n",
    "\n",
    "        # reformat x as a numpy array, incase the user input a list\n",
    "        x = np.asarray(x)\n",
    "\n",
    "        # compute the likelihood of each class\n",
    "        likelihoods = np.zeros(len(self.class_names))\n",
    "        probabilities = np.zeros(len(self.class_names))\n",
    "        \n",
    "\n",
    "        idx = 0\n",
    "        for name in self.class_names:\n",
    "            likelihoods[idx] = multivariate_gaussian_pdf(x, self.means[name], self.cov)\n",
    "            idx = idx + 1\n",
    "            \n",
    "        print(\"Likeli:\",likelihoods)\n",
    "        print(\"Priors:\", priors)\n",
    "        \n",
    "        # compute the Denominator (sum of likelihoods*priors)\n",
    "        idx = 0\n",
    "        denom = 0\n",
    "        for name in self.class_names:\n",
    "            denom = denom + (likelihoods[idx]*priors[name])\n",
    "            idx = idx + 1\n",
    "        print(\"Denom: \", denom)\n",
    "        \n",
    "         # compute the probabilities for each class \n",
    "        idx = 0 \n",
    "        for name in self.class_names:\n",
    "            probabilities[idx] = (likelihoods[idx]*priors[name]) / denom\n",
    "            idx = idx + 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        # get the indices for sorting the likelihoods (in descending order)\n",
    "        #indices_sorted = np.argsort(likelihoods)[::-1]\n",
    "        indices_sorted = np.argsort(probabilities)[::-1]\n",
    "       \n",
    "    \n",
    "    # print the predicted class and all class likelihoods\n",
    "        print('LDA Predicted Class: ' + self.class_names[indices_sorted[0]])\n",
    "        print('LDA Class Probabilities:')\n",
    "        for idx in range(len(indices_sorted)):\n",
    "            print(self.class_names[indices_sorted[idx]] + ': ' + str(probabilities[indices_sorted[idx]]))\n",
    "        \n",
    "        return probabilities\n",
    "\n",
    "\n",
    "\n",
    "model_lda = LDA('iris_data.csv')\n",
    "\n",
    "Iris_setosa_observation = [5.1, 3.5, 1.4, 0.2]\n",
    "model_lda.compute_likelihoods(Iris_setosa_observation)\n",
    "\n",
    "uninformative_priors = {\n",
    "    \"Iris-setosa\": 1 / 3,\n",
    "    \"Iris-versicolor\": 1 / 3,\n",
    "    \"Iris-virginica\": 1 / 3\n",
    "}\n",
    "model_lda.compute_probabilities(Iris_setosa_observation, uninformative_priors)\n",
    "print(model_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "incomplete-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "first = [5.5,2.4,3.8,1.1]\n",
    "second = [5.5,3.1,5,1.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "commercial-thread",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_lda' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c5da0f46e866>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nFirst\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_lda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muninformative_priors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nSECOND\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_lda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msecond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muninformative_priors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_lda' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\\nFirst\")\n",
    "model_lda.compute_probabilities(first, uninformative_priors)\n",
    "print(\"\\nSECOND\")\n",
    "model_lda.compute_probabilities(second, uninformative_priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "capital-terrorist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_lda' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-051ed80b7c2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m }\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nFirst\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel_lda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBagend_priors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nSECOND\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel_lda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msecond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBagend_priors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_lda' is not defined"
     ]
    }
   ],
   "source": [
    "Bagend_priors = {\n",
    "    \"Iris-setosa\": 0.1,\n",
    "    \"Iris-versicolor\": 0.2,\n",
    "    \"Iris-virginica\": 0.7\n",
    "}\n",
    "print(\"\\nFirst\")\n",
    "model_lda.compute_probabilities(first, Bagend_priors)\n",
    "print(\"\\nSECOND\")\n",
    "model_lda.compute_probabilities(second, Bagend_priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "corresponding-custody",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.2.2-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.9 MB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.16.5\n",
      "  Downloading numpy-1.20.1-cp37-cp37m-manylinux2010_x86_64.whl (15.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.3 MB 47.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Installing collected packages: numpy, pandas\n",
      "Successfully installed numpy-1.20.1 pandas-1.2.2\n",
      "Requirement already satisfied: numpy in /srv/conda/envs/notebook/lib/python3.7/site-packages (1.20.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-commander",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
