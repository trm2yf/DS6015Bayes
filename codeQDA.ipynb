{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "light-incident",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA Predicted Class: Iris-setosa\n",
      "QDA Class Likelihoods:\n",
      "Iris-setosa: 13.725594445123031\n",
      "Iris-versicolor: 6.846866360095676e-25\n",
      "Iris-virginica: 4.150482018069567e-40\n",
      "<__main__.QDA object at 0x7f544843ac50>\n"
     ]
    }
   ],
   "source": [
    "# This is code for Quadratic Discriminant Analysis\n",
    "# Written by William F Basener\n",
    "# University of Virginia, School of Data Science\n",
    "# For use in teaching Bayesian Machine Learning\n",
    "#\n",
    "# The code currently computes the maximum likelihood classification\n",
    "# Student is to add method to compute posterior probabilities and maximum probability classification\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def multivariate_gaussian_pdf(X, MU, SIGMA):\n",
    "    \"\"\"Code from Data Blog https://xavierbourretsicotte.github.io/MLE_Multivariate_Gaussian.html\n",
    "    Maximum Likelihood Estimator: Multivariate Gaussian Distribution\n",
    "        by Xavier Bourret Sicotte, Fri 22 June 2018\n",
    "    Returns the pdf of a multivariate Gaussian distribution\n",
    "     - X, MU are p x 1 vectors\n",
    "     - SIGMA is a p x p matrix\"\"\"\n",
    "    # Initialize and reshape\n",
    "    X = X.reshape(-1, 1)\n",
    "    MU = MU.reshape(-1, 1)\n",
    "    p, _ = SIGMA.shape\n",
    "\n",
    "    # Compute values\n",
    "    SIGMA_inv = np.linalg.inv(SIGMA)\n",
    "    denominator = np.sqrt((2 * np.pi) ** p * np.linalg.det(SIGMA))\n",
    "    exponent = -(1 / 2) * ((X - MU).T @ SIGMA_inv @ (X - MU))\n",
    "\n",
    "    # Return result\n",
    "    return float((1. / denominator) * np.exp(exponent))\n",
    "\n",
    "\n",
    "class QDA:\n",
    "    \"\"\"Creates a class for Quadratic Discriminant Analysis\n",
    "    Input:\n",
    "        fname = file name for a csv file, must have one column labeled \"class\" and the rest numeric data\n",
    "    Methods:\n",
    "        compute_probabilities = given an input observation computes the likelihood for each class and the GML class\n",
    "        compute_probabilities: given an input observation and prior probabilities,\n",
    "            computes the posterior probabilities for each class and most probable class\"\"\"\n",
    "\n",
    "    def __init__(self, fname):\n",
    "        # reads the data and computes the statistics needed for classification\n",
    "\n",
    "        # read the iris data as a Pandas data frame\n",
    "        df = pd.read_csv(fname)\n",
    "\n",
    "        # separate the class labels from the rest of the data\n",
    "        # we are assuming the column name with class labels is 'Class'\n",
    "        # and all other columns are numeric\n",
    "        self.data_labels = df.loc[:]['Class']\n",
    "        self.data = np.asarray(df.drop('Class', axis=1, inplace=False))\n",
    "\n",
    "        # get information about the dimensions the data\n",
    "        self.num_rows, self.num_cols = self.data.shape\n",
    "\n",
    "        # get the class names as an array of strings\n",
    "        self.class_names = np.unique(self.data_labels)\n",
    "\n",
    "        # determine number of observations in each class\n",
    "        self.num_obs = dict()\n",
    "        for name in self.class_names:\n",
    "            self.num_obs[name] = sum(self.data_labels == name)\n",
    "\n",
    "        # compute the mean of each class\n",
    "        self.means = dict()\n",
    "        for name in self.class_names:\n",
    "            self.means[name] = np.mean(self.data[self.data_labels == name, :], 0)\n",
    "\n",
    "        # compute the covariance matrix of each class\n",
    "        self.covs = dict()\n",
    "        for name in self.class_names:\n",
    "            self.covs[name] = np.cov(np.transpose(self.data[self.data_labels == name, :]))\n",
    "\n",
    "    def compute_likelihoods(self, x):\n",
    "        # compute and output the likelihood of each class and the maximum likelihood class\n",
    "\n",
    "        # check that the input data x has the correct number of rows\n",
    "        if not (len(x) == self.num_cols):\n",
    "            print('Data vector has wrong number of values.')\n",
    "            return -1\n",
    "\n",
    "        # reformat x as a numpy array, incase the user input a list\n",
    "        x = np.asarray(x)\n",
    "\n",
    "        # compute the likelihood of each class\n",
    "        likelihoods = np.zeros(len(self.class_names))\n",
    "        idx = 0\n",
    "        for name in self.class_names:\n",
    "            likelihoods[idx] = multivariate_gaussian_pdf(x, self.means[name], self.covs[name])\n",
    "            idx = idx + 1\n",
    "        # get the indices for sorting the likelihoods (in descending order)\n",
    "        indices_sorted = np.argsort(likelihoods)[::-1]\n",
    "\n",
    "        # print the predicted class and all class likelihoods\n",
    "        print('QDA Predicted Class: ' + self.class_names[indices_sorted[0]])\n",
    "        print('QDA Class Likelihoods:')\n",
    "        for idx in range(len(indices_sorted)):\n",
    "            print(self.class_names[indices_sorted[idx]] + ': ' + str(likelihoods[indices_sorted[idx]]))\n",
    "\n",
    "        # return the likelihoods\n",
    "        return likelihoods\n",
    "\n",
    "    def compute_probabilities(self, x, priors):\n",
    "        # compute and output the probability of each class and the maximum probability class\n",
    "        return -1\n",
    "\n",
    "\n",
    "model_qda = QDA('iris_data.csv')\n",
    "\n",
    "Iris_setosa_observation = [5.1, 3.5, 1.4, 0.2]\n",
    "model_qda.compute_likelihoods(Iris_setosa_observation)\n",
    "\n",
    "uninformative_priors = {\n",
    "    \"Iris-setosa\": 1 / 3,\n",
    "    \"Iris-versicolor\": 1 / 3,\n",
    "    \"Iris-virginica\": 1 / 3\n",
    "}\n",
    "model_qda.compute_probabilities(Iris_setosa_observation, uninformative_priors)\n",
    "print(model_qda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "talented-pollution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likeli: [1.37255944e+01 6.84686636e-25 4.15048202e-40]\n",
      "Priors: {'Iris-setosa': 0.3333333333333333, 'Iris-versicolor': 0.3333333333333333, 'Iris-virginica': 0.3333333333333333}\n",
      "Denom:  4.575198148374343\n",
      "QDA Predicted Class: Iris-setosa\n",
      "QDA Class Probabilities:\n",
      "Iris-setosa: 1.0\n",
      "Iris-versicolor: 4.9883933169309835e-26\n",
      "Iris-virginica: 3.023899645777684e-41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 4.98839332e-26, 3.02389965e-41])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is code for Quadratic Discriminant Analysis\n",
    "# Written by William F Basener\n",
    "# University of Virginia, School of Data Science\n",
    "# For use in teaching Bayesian Machine Learning\n",
    "#\n",
    "# The code currently computes the maximum likelihood classification\n",
    "# Student is to add method to compute posterior probabilities and maximum probability classification\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def multivariate_gaussian_pdf(X, MU, SIGMA):\n",
    "    \"\"\"Code from Data Blog https://xavierbourretsicotte.github.io/MLE_Multivariate_Gaussian.html\n",
    "    Maximum Likelihood Estimator: Multivariate Gaussian Distribution\n",
    "        by Xavier Bourret Sicotte, Fri 22 June 2018\n",
    "    Returns the pdf of a multivariate Gaussian distribution\n",
    "     - X, MU are p x 1 vectors\n",
    "     - SIGMA is a p x p matrix\"\"\"\n",
    "    # Initialize and reshape\n",
    "    X = X.reshape(-1, 1)\n",
    "    MU = MU.reshape(-1, 1)\n",
    "    p, _ = SIGMA.shape\n",
    "\n",
    "    # Compute values\n",
    "    SIGMA_inv = np.linalg.inv(SIGMA)\n",
    "    denominator = np.sqrt((2 * np.pi) ** p * np.linalg.det(SIGMA))\n",
    "    exponent = -(1 / 2) * ((X - MU).T @ SIGMA_inv @ (X - MU))\n",
    "\n",
    "    # Return result\n",
    "    return float((1. / denominator) * np.exp(exponent))\n",
    "\n",
    "\n",
    "class QDA:\n",
    "    \"\"\"Creates a class for Quadratic Discriminant Analysis\n",
    "    Input:\n",
    "        fname = file name for a csv file, must have one column labeled \"class\" and the rest numeric data\n",
    "    Methods:\n",
    "        compute_probabilities = given an input observation computes the likelihood for each class and the GML class\n",
    "        compute_probabilities: given an input observation and prior probabilities,\n",
    "            computes the posterior probabilities for each class and most probable class\"\"\"\n",
    "\n",
    "    def __init__(self, fname):\n",
    "        # reads the data and computes the statistics needed for classification\n",
    "\n",
    "        # read the iris data as a Pandas data frame\n",
    "        df = pd.read_csv(fname)\n",
    "\n",
    "        # separate the class labels from the rest of the data\n",
    "        # we are assuming the column name with class labels is 'Class'\n",
    "        # and all other columns are numeric\n",
    "        self.data_labels = df.loc[:]['Class']\n",
    "        self.data = np.asarray(df.drop('Class', axis=1, inplace=False))\n",
    "\n",
    "        # get information about the dimensions the data\n",
    "        self.num_rows, self.num_cols = self.data.shape\n",
    "\n",
    "        # get the class names as an array of strings\n",
    "        self.class_names = np.unique(self.data_labels)\n",
    "\n",
    "        # determine number of observations in each class\n",
    "        self.num_obs = dict()\n",
    "        for name in self.class_names:\n",
    "            self.num_obs[name] = sum(self.data_labels == name)\n",
    "\n",
    "        # compute the mean of each class\n",
    "        self.means = dict()\n",
    "        for name in self.class_names:\n",
    "            self.means[name] = np.mean(self.data[self.data_labels == name, :], 0)\n",
    "\n",
    "        # compute the covariance matrix of each class\n",
    "        self.covs = dict()\n",
    "        for name in self.class_names:\n",
    "            self.covs[name] = np.cov(np.transpose(self.data[self.data_labels == name, :]))\n",
    "\n",
    "    def compute_likelihoods(self, x):\n",
    "        # compute and output the likelihood of each class and the maximum likelihood class\n",
    "\n",
    "        # check that the input data x has the correct number of rows\n",
    "        if not (len(x) == self.num_cols):\n",
    "            print('Data vector has wrong number of values.')\n",
    "            return -1\n",
    "\n",
    "        # reformat x as a numpy array, incase the user input a list\n",
    "        x = np.asarray(x)\n",
    "\n",
    "        # compute the likelihood of each class\n",
    "        likelihoods = np.zeros(len(self.class_names))\n",
    "        idx = 0\n",
    "        for name in self.class_names:\n",
    "            likelihoods[idx] = multivariate_gaussian_pdf(x, self.means[name], self.covs[name])\n",
    "            idx = idx + 1\n",
    "        # get the indices for sorting the likelihoods (in descending order)\n",
    "        indices_sorted = np.argsort(likelihoods)[::-1]\n",
    "\n",
    "        # print the predicted class and all class likelihoods\n",
    "        print('QDA Predicted Class: ' + self.class_names[indices_sorted[0]])\n",
    "        print('QDA Class Likelihoods:')\n",
    "        for idx in range(len(indices_sorted)):\n",
    "            print(self.class_names[indices_sorted[idx]] + ': ' + str(likelihoods[indices_sorted[idx]]))\n",
    "\n",
    "        # return the likelihoods\n",
    "        return likelihoods\n",
    "\n",
    "    def compute_probabilities(self, x, priors):\n",
    "        # compute and output the probability of each class and the maximum probability class\n",
    "\n",
    "        # check that the input data x has the correct number of rows\n",
    "        if not (len(x) == self.num_cols):\n",
    "            print('Data vector has wrong number of values.')\n",
    "            return -1\n",
    "\n",
    "        # reformat x as a numpy array, incase the user input a list\n",
    "        x = np.asarray(x)\n",
    "\n",
    "        # compute the likelihood of each class\n",
    "        likelihoods = np.zeros(len(self.class_names))\n",
    "        probabilities = np.zeros(len(self.class_names))\n",
    "        \n",
    "        idx = 0\n",
    "        for name in self.class_names:\n",
    "            likelihoods[idx] = multivariate_gaussian_pdf(x, self.means[name], self.covs[name])\n",
    "            idx = idx + 1\n",
    "            \n",
    "        print(\"Likeli:\",likelihoods)\n",
    "        print(\"Priors:\", priors)\n",
    "        \n",
    "        # compute the Denominator (sum of likelihoods*priors)\n",
    "        idx = 0\n",
    "        denom = 0\n",
    "        for name in self.class_names:\n",
    "            denom = denom + (likelihoods[idx]*priors[name])\n",
    "            idx = idx + 1\n",
    "        print(\"Denom: \", denom)\n",
    "        \n",
    "        \n",
    "         # compute the probabilities for each class \n",
    "        idx = 0 \n",
    "        for name in self.class_names:\n",
    "            probabilities[idx] = (likelihoods[idx]*priors[name]) / denom\n",
    "            idx = idx + 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        # get the indices for sorting the likelihoods (in descending order)\n",
    "        #indices_sorted = np.argsort(likelihoods)[::-1]\n",
    "        indices_sorted = np.argsort(probabilities)[::-1]\n",
    "       \n",
    "    \n",
    "    # print the predicted class and all class likelihoods\n",
    "        print('QDA Predicted Class: ' + self.class_names[indices_sorted[0]])\n",
    "        print('QDA Class Probabilities:')\n",
    "        for idx in range(len(indices_sorted)):\n",
    "            print(self.class_names[indices_sorted[idx]] + ': ' + str(probabilities[indices_sorted[idx]]))\n",
    "        \n",
    "        return probabilities\n",
    "\n",
    "\n",
    "model_qda = QDA('iris_data.csv')\n",
    "\n",
    "Iris_setosa_observation = [5.1, 3.5, 1.4, 0.2]\n",
    "#model_qda.compute_likelihoods(Iris_setosa_observation)\n",
    "\n",
    "uninformative_priors = {\n",
    "    \"Iris-setosa\": 1 / 3,\n",
    "    \"Iris-versicolor\": 1 / 3,\n",
    "    \"Iris-virginica\": 1 / 3\n",
    "}\n",
    "model_qda.compute_probabilities(Iris_setosa_observation, uninformative_priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "south-depression",
   "metadata": {},
   "outputs": [],
   "source": [
    "first = [5.5,2.4,3.8,1.1]\n",
    "second = [5.5,3.1,5,1.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "practical-incidence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First\n",
      "Likeli: [6.96249484e-52 2.56791233e+00 7.67146865e-05]\n",
      "Priors: {'Iris-setosa': 0.3333333333333333, 'Iris-versicolor': 0.3333333333333333, 'Iris-virginica': 0.3333333333333333}\n",
      "Denom:  0.8559963490929874\n",
      "QDA Predicted Class: Iris-versicolor\n",
      "QDA Class Probabilities:\n",
      "Iris-versicolor: 0.9999701265523081\n",
      "Iris-virginica: 2.987344769195638e-05\n",
      "Iris-setosa: 2.711263447644606e-52\n",
      "\n",
      "SECOND\n",
      "Likeli: [2.07142499e-105 3.30607636e-003 4.29103948e-003]\n",
      "Priors: {'Iris-setosa': 0.3333333333333333, 'Iris-versicolor': 0.3333333333333333, 'Iris-virginica': 0.3333333333333333}\n",
      "Denom:  0.0025323719450157847\n",
      "QDA Predicted Class: Iris-virginica\n",
      "QDA Class Probabilities:\n",
      "Iris-virginica: 0.5648248061588753\n",
      "Iris-versicolor: 0.43517519384112463\n",
      "Iris-setosa: 2.726593926101304e-103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.72659393e-103, 4.35175194e-001, 5.64824806e-001])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nFirst\")\n",
    "model_qda.compute_probabilities(first, uninformative_priors)\n",
    "print(\"\\nSECOND\")\n",
    "model_qda.compute_probabilities(second, uninformative_priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "limiting-auditor",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bagend_priors = {\n",
    "    \"Iris-setosa\": 0.1,\n",
    "    \"Iris-versicolor\": 0.2,\n",
    "    \"Iris-virginica\": 0.7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "labeled-withdrawal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First\n",
      "Likeli: [6.96249484e-52 2.56791233e+00 7.67146865e-05]\n",
      "Priors: {'Iris-setosa': 0.1, 'Iris-versicolor': 0.2, 'Iris-virginica': 0.7}\n",
      "Denom:  0.5136361667990312\n",
      "QDA Predicted Class: Iris-versicolor\n",
      "QDA Class Probabilities:\n",
      "Iris-versicolor: 0.9998954507411951\n",
      "Iris-virginica: 0.00010454925880481196\n",
      "Iris-setosa: 1.3555304878994901e-52\n",
      "\n",
      "SECOND\n",
      "Likeli: [2.07142499e-105 3.30607636e-003 4.29103948e-003]\n",
      "Priors: {'Iris-setosa': 0.1, 'Iris-versicolor': 0.2, 'Iris-virginica': 0.7}\n",
      "Denom:  0.0036649429064580428\n",
      "QDA Predicted Class: Iris-virginica\n",
      "QDA Class Probabilities:\n",
      "Iris-virginica: 0.8195837457481517\n",
      "Iris-versicolor: 0.1804162542518483\n",
      "Iris-setosa: 5.651997976619857e-104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5.65199798e-104, 1.80416254e-001, 8.19583746e-001])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nFirst\")\n",
    "model_qda.compute_probabilities(first, Bagend_priors)\n",
    "print(\"\\nSECOND\")\n",
    "model_qda.compute_probabilities(second, Bagend_priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-gathering",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
